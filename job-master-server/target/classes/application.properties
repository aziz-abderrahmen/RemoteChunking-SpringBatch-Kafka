spring.application.name=job-master-server
server.port=7777

logging.level.org.springframework.web=INFO
logging.level.org.springframework.cloud.stream=DEBUG
logging.level.org.springframework.cloud.task=DEBUG
logging.level.org.apache.kafka=ERROR
logging.level.org.hibernate=TRACE

# db config
spring.jpa.database-platform=com.cfa.configs.SQLiteDialectConfig
spring.jpa.properties.hibernate.dialect=com.cfa.configs.SQLiteDialectConfig
spring.datasource.url=jdbc:sqlite:sqlitesamplecfa.db
#spring.jpa.hibernate.ddl-auto=create
spring.jpa.hibernate.hbm2ddl.auto
spring.datasource.driver-class-name=org.sqlite.JDBC
spring.datasource.username=cfa
spring.datasource.password=admin

# job config
spring.batch.job.enabled=false
spring.cloud.task.batch.events.job-execution.enabled=false

# output
spring.cloud.stream.bindings.input.destination=workern
spring.cloud.stream.bindings.input.group=product
spring.cloud.stream.bindings.input.binder=kafka
# input
# Spring cloud stream kafka config
spring.cloud.stream.bindings.output.destination=workern
spring.cloud.stream.bindings.output.group=product
spring.cloud.stream.bindings.output.binder=kafka
spring.cloud.stream.bindings.output.producer.error-channel-enabled=true
spring.cloud.stream.bindings.output.producer.partition-count=1

spring.cloud.stream.bindings.error.destination=errors
spring.cloud.stream.kafka.binder.autoAddPartitions=true
spring.cloud.stream.kafka.binder.min-partition-count=1

spring.main.allow-bean-definition-overriding=true
management.health.binders.enabled=true

spring.kafka.producer.key-serializer=com.cfa.configs.hazelcast.serializer.CustomSerializer
spring.kafka.producer.value-serializer=com.cfa.configs.hazelcast.serializer.CustomSerializer
spring.kafka.consumer.key-deserializer=com.cfa.configs.hazelcast.deserializer.CustomDeserializer
spring.kafka.consumer.value-deserializer=com.cfa.configs.hazelcast.deserializer.CustomDeserializer

spring.kafka.consumer.properties.spring.json.trusted.packages=*